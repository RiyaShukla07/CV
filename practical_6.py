# -*- coding: utf-8 -*-
"""Practical_6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AYis-M8pQ1Wm-D5m7CnseQiTI6pzUoDZ
"""

import numpy as np
import matplotlib.pyplot as plt

# Create 100x100 black image
image = np.zeros((100, 100))

# Add white square object
image[40:70, 40:70] = 255
# -------------------------------
# Step 2: Sliding Window Detection
# -------------------------------

window_size = 20
stride = 5
threshold = 200  # Brightness threshold

detections = []

for y in range(0, 100 - window_size + 1, stride):
    for x in range(0, 100 - window_size + 1, stride):

        # Extract window
        window = image[y:y+window_size, x:x+window_size]

        # Feature Extraction (Mean Intensity)
        feature = np.mean(window)

        # Simple Classification
        if feature > threshold:
            detections.append((x, y))
            # -------------------------------
# Step 3: Visualize Results
# -------------------------------

plt.figure(figsize=(6,6))
plt.imshow(image, cmap='gray')

# Draw bounding boxes
for (x, y) in detections:
    rect = plt.Rectangle(
        (x, y),
        window_size,
        window_size,
        edgecolor='red',
        facecolor='none',
        linewidth=2
    )
    plt.gca().add_patch(rect)

plt.title("R-CNN Concept Demonstration")
plt.axis("off")
plt.show()

# -------------------------------
# Print Detected Coordinates
# -------------------------------

print("Detected Object Regions (Top-Left Coordinates):")
for d in detections:
    print("Object detected at:", d)

!pip install opencv-contrib-python torch torchvision

# import numpy as np
# import matplotlib.pyplot as plt
import torch
import torchvision
import cv2
from google.colab import files
from PIL import Image
import io

print("\nNow upload your own image:")
uploaded = files.upload()

image_name = list(uploaded.keys())[0]
custom_image = Image.open(io.BytesIO(uploaded[image_name])).convert("RGB")

# Convert to numpy
image_np = np.array(custom_image)

# =====================================================
# PART 1: Your Original Sliding Window Detection
# =====================================================

gray_image = custom_image.convert("L")
gray_image = gray_image.resize((200, 200))
gray_image = np.array(gray_image)

window_size = 40
stride = 20
threshold = 180

detections_custom = []
height, width = gray_image.shape

for y in range(0, height - window_size + 1, stride):
    for x in range(0, width - window_size + 1, stride):
        window = gray_image[y:y+window_size, x:x+window_size]
        feature = np.mean(window)
        if feature > threshold:
            detections_custom.append((x, y))

plt.figure(figsize=(6,6))
plt.imshow(gray_image, cmap='gray')

for (x, y) in detections_custom:
    rect = plt.Rectangle((x, y), window_size, window_size,
                         edgecolor='red', facecolor='none', linewidth=2)
    plt.gca().add_patch(rect)

plt.title("Sliding Window Detection")
plt.axis("off")
plt.show()

print("Sliding Window Detections:")
for d in detections_custom:
    print("Object detected at:", d)


# =====================================================
# PART 2: REAL R-CNN STYLE DETECTION
# =====================================================

print("\nRunning Real R-CNN Detection...")

# Load pretrained Faster R-CNN (Improved R-CNN family)
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor()
])

img_tensor = transform(custom_image).unsqueeze(0)

with torch.no_grad():
    outputs = model(img_tensor)

boxes = outputs[0]['boxes']
scores = outputs[0]['scores']
labels = outputs[0]['labels']

# COCO Class Labels
COCO_CLASSES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
    'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
    'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv',
    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear',
    'hair drier', 'toothbrush'
]

# Plot detections
plt.figure(figsize=(8,8))
plt.imshow(custom_image)

for i in range(len(boxes)):
    if scores[i] > 0.5:
        x1, y1, x2, y2 = boxes[i]

        rect = plt.Rectangle(
            (x1, y1),
            x2 - x1,
            y2 - y1,
            edgecolor='yellow',
            facecolor='none',
            linewidth=2
        )
        plt.gca().add_patch(rect)

        label = COCO_CLASSES[labels[i]]
        plt.text(x1, y1, label,
                 color='black',
                 fontsize=10,
                 bbox=dict(facecolor='yellow', alpha=0.6))

plt.title("Real R-CNN Object Detection Result")
plt.axis("off")
plt.show()

# ===========================================
# R-CNN Concept + Real Faster R-CNN Detection
# ===========================================

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from google.colab import files
import torch
import torchvision
from torchvision import transforms

# -------------------------------
# STEP 1: Upload Image
# -------------------------------
print("Upload an image for detection:")
uploaded = files.upload()
image_name = list(uploaded.keys())[0]

# Open image in RGB
user_image = Image.open(image_name).convert("RGB")
image_np = np.array(user_image)
img_height, img_width = image_np.shape[:2]

# -------------------------------
# STEP 2: Sliding Window Demo (Optional)
# -------------------------------
# Grayscale & resized version for sliding window
gray_image = user_image.convert("L").resize((200, 200))
gray_np = np.array(gray_image)

window_size = 40
stride = 20
threshold = 180
detections_custom = []

for y in range(0, gray_np.shape[0] - window_size + 1, stride):
    for x in range(0, gray_np.shape[1] - window_size + 1, stride):
        window = gray_np[y:y+window_size, x:x+window_size]
        if np.mean(window) > threshold:
            detections_custom.append((x, y))

# Show sliding window result
plt.figure(figsize=(6,6))
plt.imshow(gray_np, cmap='gray')
for (x, y) in detections_custom:
    plt.gca().add_patch(plt.Rectangle((x, y), window_size, window_size,
                                      edgecolor='red', facecolor='none', linewidth=2))
plt.title("Sliding Window Detection")
plt.axis("off")
plt.show()

print("Sliding Window Detections (approx.):")
for d in detections_custom:
    print("Object detected at:", d)

# -------------------------------
# STEP 3: Real Faster R-CNN Detection
# -------------------------------
print("\nRunning real R-CNN detection on uploaded image...")

# Load pretrained Faster R-CNN model
model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights="DEFAULT")
model.eval()

# Transform the image
transform = transforms.Compose([transforms.ToTensor()])
img_tensor = transform(user_image).unsqueeze(0)

# Run detection
with torch.no_grad():
    outputs = model(img_tensor)

boxes = outputs[0]['boxes']
scores = outputs[0]['scores']
labels = outputs[0]['labels']

# COCO class labels
COCO_CLASSES = [
    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',
    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',
    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',
    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
    'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',
    'baseball glove', 'skateboard', 'surfboard', 'tennis racket',
    'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',
    'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv',
    'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator',
    'book', 'clock', 'vase', 'scissors', 'teddy bear',
    'hair drier', 'toothbrush'
]

# Confidence threshold
CONF_THRESH = 0.3

# Show results
plt.figure(figsize=(10,10))
plt.imshow(user_image)

for i in range(len(boxes)):
    if scores[i] >= CONF_THRESH:
        x1, y1, x2, y2 = boxes[i]

        # Draw bounding box
        plt.gca().add_patch(plt.Rectangle(
            (x1, y1), x2-x1, y2-y1,
            edgecolor='yellow', facecolor='none', linewidth=2))

        # Add label + confidence
        plt.text(x1, y1-5,
                 f"{COCO_CLASSES[labels[i]]} ({scores[i]:.2f})",
                 color='black', fontsize=10,
                 bbox=dict(facecolor='yellow', alpha=0.6))

plt.title("Faster R-CNN Object Detection")
plt.axis("off")
plt.show()